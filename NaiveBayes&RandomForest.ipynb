{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-40-93.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SparkSession</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=SparkSession>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "     .appName(\"SparkSession\") \\\n",
    "     .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext \n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "|      asin|helpful|overall|          reviewText| reviewTime|    reviewerID|        reviewerName|             summary|unixReviewTime|\n",
      "+----------+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "|B00002STAU| [0, 0]|    5.0|this is a old cla...|07 30, 2012|A1G0VFQ9198IUF|                  al|           a classic|    1343606400|\n",
      "|B00002STAU| [2, 2]|    4.0|This game is more...|02 21, 2001| AXUOVXIGF9CKC|      \"bigdcaldavis\"|  good fighting game|     982713600|\n",
      "|B00002STAU| [0, 0]|    5.0|If you love WWF n...|11 14, 2011|A15JTJXQXO22JJ|           Chad Frey|WWF Wrestlemania ...|    1321228800|\n",
      "|B00002STAU| [1, 1]|    4.0|I had WWF Wrestle...|08 10, 2008| ANRNG7OAARR70|D. Hensley \"Horro...|wrestling game wi...|    1218326400|\n",
      "|B00002STAU| [0, 0]|    4.0|I have to admit I...|07 24, 2009|A2ZFYB6WY3RG93|        Raqel Redfox|           A Classic|    1248393600|\n",
      "|B00002STAU| [1, 1]|    5.0|This game was ama...|02 27, 2013|A3J8ABVGK7ZL6H|         SideshowBob|The Best Wrestlin...|    1361923200|\n",
      "|B00002STAU| [0, 0]|    4.0|This right here i...| 04 1, 2014|A3DE438TF1A958|        thomas henry|wrestling at it's...|    1396310400|\n",
      "|B00002SVP7| [0, 0]|    3.0|The Rampage Editi...|04 16, 2013|A2CJJSS6OD4K2G|     anita reichmann|A few new levels ...|    1366070400|\n",
      "|B00002SVP7|[7, 13]|    2.0|Remember the mome...| 05 3, 2006|A2ICW5OUWX2A2V|                 Ian|                WTF?|    1146614400|\n",
      "|B00002SVP7| [2, 7]|    2.0|Back in 1993 Sega...|06 20, 2004|A319SKSB556033|Inspector Gadget ...|           Bo-oring!|    1087689600|\n",
      "+----------+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.json(\"s3://502-project/amazon_game_data\")\n",
    "data.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|overall|          reviewText|\n",
      "+-------+--------------------+\n",
      "|    5.0|this is a old cla...|\n",
      "|    4.0|this game is more...|\n",
      "|    5.0|if you love wwf n...|\n",
      "|    4.0|i had wwf wrestle...|\n",
      "|    4.0|i have to admit i...|\n",
      "+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove all unnecessary columns and only keep predictor feature and label\n",
    "drop_list = ['asin', 'helpful', 'reviewTime', 'reviewerID', 'reviewerName', 'summary', 'unixReviewTime']\n",
    "data = data.select([column for column in data.columns if column not in drop_list])\n",
    "\n",
    "# format text column\n",
    "data.createOrReplaceTempView(\"data\")\n",
    "data=spark.sql(\"SELECT overall, LOWER(reviewText) AS reviewText FROM data\")\n",
    "data.show(5)\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|overall| count|\n",
      "+-------+------+\n",
      "|    5.0|594971|\n",
      "|    4.0|210922|\n",
      "|    1.0|112789|\n",
      "|    3.0| 97153|\n",
      "|    2.0| 59477|\n",
      "+-------+------+\n",
      "\n",
      "+------------+-----+\n",
      "|  reviewText|count|\n",
      "+------------+-----+\n",
      "|            |  246|\n",
      "|  great game|  100|\n",
      "|        good|   88|\n",
      "|       great|   85|\n",
      "|   good game|   66|\n",
      "|   excellent|   50|\n",
      "|     love it|   44|\n",
      "|     awesome|   36|\n",
      "| works great|   36|\n",
      "|   very good|   34|\n",
      "| great game!|   29|\n",
      "|   excelente|   28|\n",
      "|         fun|   28|\n",
      "|        nice|   27|\n",
      "|          ok|   25|\n",
      "|     perfect|   25|\n",
      "|awesome game|   22|\n",
      "|    excelent|   21|\n",
      "|    fun game|   20|\n",
      "| great game.|   17|\n",
      "+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inspect data\n",
    "from pyspark.sql.functions import col\n",
    "data.groupBy(\"overall\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()\n",
    "\n",
    "data.groupBy(\"reviewText\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/hadoop/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package words to /home/hadoop/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n",
      "[nltk_data] Downloading package punkt to /home/hadoop/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_lst=stopwords.words('english')+['1','2','3','4','5','6','7','8','9','0',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "# regular expression tokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"reviewText\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "# stop words\n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(stopwords_lst)\n",
    "# bag of words count\n",
    "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=10000, minDF=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|overall|          reviewText|               words|            filtered|            features|label|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|    5.0|this is a old cla...|[this, is, a, old...|[old, classic, wr...|(10000,[0,41,51,3...|  0.0|\n",
      "|    4.0|this game is more...|[this, game, is, ...|[game, one, one, ...|(10000,[0,2,5,7,5...|  1.0|\n",
      "|    5.0|if you love wwf n...|[if, you, love, w...|[love, wwf, calle...|(10000,[0,6,20,23...|  0.0|\n",
      "|    4.0|i had wwf wrestle...|[i, had, wwf, wre...|[wwf, wrestlemani...|(10000,[0,1,2,3,4...|  1.0|\n",
      "|    4.0|i have to admit i...|[i, have, to, adm...|[admit, started, ...|(10000,[0,1,3,4,7...|  1.0|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "label_stringIdx = StringIndexer(inputCol = \"overall\", outputCol = \"label\")\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])\n",
    "# Fit the pipeline to training documents.\n",
    "pipelineFit = pipeline.fit(data)\n",
    "dataset = pipelineFit.transform(data)\n",
    "dataset.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label to stringIdx: overall->label: 1->3, 2->4, 3->2, 4->1, 5->0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 752381\n",
      "Test Dataset Count: 322931\n"
     ]
    }
   ],
   "source": [
    "# set seed for reproducibility\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-------+------------------------------+-----+----------+\n",
      "|                    reviewText|overall|                   probability|label|prediction|\n",
      "+------------------------------+-------+------------------------------+-----+----------+\n",
      "|i originally wrote a review...|    5.0|[1.0,1.0880086880649125E-16...|  0.0|       0.0|\n",
      "|cuando uno termina este jue...|    5.0|[1.0,1.0437689243605692E-16...|  0.0|       0.0|\n",
      "|i recently bought this psp ...|    5.0|[1.0,9.254118904297825E-17,...|  0.0|       0.0|\n",
      "|este es un juego obligatori...|    5.0|[1.0,8.404487436486103E-17,...|  0.0|       0.0|\n",
      "|the playstation vita tends ...|    4.0|[1.0,7.939853558907832E-17,...|  1.0|       0.0|\n",
      "|this video game system live...|    5.0|[1.0,7.544758352543615E-17,...|  0.0|       0.0|\n",
      "|since nintendo orignally ca...|    5.0|[1.0,6.850183256187071E-17,...|  0.0|       0.0|\n",
      "|compre mi xbox 360 con la f...|    4.0|[1.0,6.695904736345189E-17,...|  1.0|       0.0|\n",
      "|(es) excelente producto, mi...|    5.0|[1.0,5.455670281057381E-17,...|  0.0|       0.0|\n",
      "|i think i'll start by letti...|    5.0|[1.0,4.8711683090069886E-17...|  0.0|       0.0|\n",
      "+------------------------------+-------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model trarining\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "model = nb.fit(trainingData)\n",
    "\n",
    "# run model on test data\n",
    "predictions = model.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"reviewText\",\"overall\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5868996977927786"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-------+------------------------------+-----+----------+\n",
      "|                    reviewText|overall|                   probability|label|prediction|\n",
      "+------------------------------+-------+------------------------------+-----+----------+\n",
      "|love it! love it! love it! ...|    5.0|[0.5852702080661911,0.18720...|  0.0|       0.0|\n",
      "|i think it's great but that...|    5.0|[0.5850881217327596,0.18728...|  0.0|       0.0|\n",
      "|great game so far with amaz...|    5.0|[0.5850881217327596,0.18728...|  0.0|       0.0|\n",
      "|absolutely. amazing. this g...|    5.0|[0.5850881217327596,0.18728...|  0.0|       0.0|\n",
      "|so i waited 2 weeks to writ...|    5.0|[0.5850881217327596,0.18728...|  0.0|       0.0|\n",
      "|great game its awesome its ...|    5.0|[0.5850881217327596,0.18728...|  0.0|       0.0|\n",
      "|i loved this game when it w...|    5.0|[0.5850881217327596,0.18728...|  0.0|       0.0|\n",
      "|these are amazing! comforta...|    5.0|[0.58436512613015,0.1871791...|  0.0|       0.0|\n",
      "|this is an amazing machine,...|    5.0|[0.5842401444165816,0.18793...|  0.0|       0.0|\n",
      "|far cry 3 is simply amazing...|    5.0|[0.5842377531388553,0.18807...|  0.0|       0.0|\n",
      "+------------------------------+-------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model trarining\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n",
    "rfModel = rf.fit(trainingData)\n",
    "\n",
    "# run model on test data\n",
    "predictions = rfModel.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"reviewText\",\"overall\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3947844044365289"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three Label Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.createOrReplaceTempView('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall=1 or 2, attitue = negative \n",
    "# overall=3, attitue = neural\n",
    "# overall=4 or 5, attitue = positive\n",
    "from pyspark.sql import functions as F\n",
    "df=data.withColumn('attitude', F.when(F.col('overall')<3,'negative').otherwise(F.when( F.col('overall') == 3,'neutral').otherwise('positive')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------+\n",
      "|overall|          reviewText|attitude|\n",
      "+-------+--------------------+--------+\n",
      "|    5.0|this is a old cla...|positive|\n",
      "|    4.0|this game is more...|positive|\n",
      "|    5.0|if you love wwf n...|positive|\n",
      "|    4.0|i had wwf wrestle...|positive|\n",
      "|    4.0|i have to admit i...|positive|\n",
      "|    5.0|this game was ama...|positive|\n",
      "|    4.0|this right here i...|positive|\n",
      "|    3.0|the rampage editi...| neutral|\n",
      "|    2.0|remember the mome...|negative|\n",
      "|    2.0|back in 1993 sega...|negative|\n",
      "+-------+--------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+--------+------+\n",
      "|attitude| count|\n",
      "+--------+------+\n",
      "|positive|805893|\n",
      "|negative|172266|\n",
      "| neutral| 97153|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)\n",
    "df.groupBy(\"attitude\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------+--------------------+--------------------+--------------------+-----+\n",
      "|overall|          reviewText|attitude|               words|            filtered|            features|label|\n",
      "+-------+--------------------+--------+--------------------+--------------------+--------------------+-----+\n",
      "|    5.0|this is a old cla...|positive|[this, is, a, old...|[old, classic, wr...|(10000,[0,41,51,3...|  0.0|\n",
      "|    4.0|this game is more...|positive|[this, game, is, ...|[game, one, one, ...|(10000,[0,2,5,7,5...|  0.0|\n",
      "|    5.0|if you love wwf n...|positive|[if, you, love, w...|[love, wwf, calle...|(10000,[0,6,20,23...|  0.0|\n",
      "|    4.0|i had wwf wrestle...|positive|[i, had, wwf, wre...|[wwf, wrestlemani...|(10000,[0,1,2,3,4...|  0.0|\n",
      "|    4.0|i have to admit i...|positive|[i, have, to, adm...|[admit, started, ...|(10000,[0,1,3,4,7...|  0.0|\n",
      "+-------+--------------------+--------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_stringIdx = StringIndexer(inputCol = \"attitude\", outputCol = \"label\")\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])\n",
    "# Fit the pipeline to training documents.\n",
    "pipelineFit = pipeline.fit(df)\n",
    "dataset = pipelineFit.transform(df)\n",
    "dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 752381\n",
      "Test Dataset Count: 322931\n"
     ]
    }
   ],
   "source": [
    "# set seed for reproducibility\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|                    reviewText|attitude|                   probability|label|prediction|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|yes, i am writing this revi...|positive|[1.0,8.786606125898127E-17,...|  0.0|       0.0|\n",
      "|what is the best selling an...|positive|[1.0,8.623355319727688E-17,...|  0.0|       0.0|\n",
      "|i got my sony psp about two...|positive|[1.0,8.002400118234624E-17,...|  0.0|       0.0|\n",
      "|i have bought the 3g/wifi v...|positive|[1.0,5.786357441689283E-17,...|  0.0|       0.0|\n",
      "|i love this system, it has ...|positive|[1.0,4.5055585060084E-17,1....|  0.0|       0.0|\n",
      "|--update 12/15---ok, so aft...|positive|[1.0,3.527338995139392E-17,...|  0.0|       0.0|\n",
      "|many months ago, my friend ...|positive|[1.0,3.4427716290248495E-17...|  0.0|       0.0|\n",
      "|i have been playing video g...|positive|[1.0,2.32021759551896E-17,7...|  0.0|       0.0|\n",
      "|okay, i'm a complete beginn...|positive|[1.0,2.277027035057847E-17,...|  0.0|       0.0|\n",
      "|ok - let me start off by sa...|positive|[1.0,2.2537689146781017E-17...|  0.0|       0.0|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "model = nb.fit(trainingData)\n",
    "\n",
    "# run model on test data\n",
    "predictions = model.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"reviewText\",\"attitude\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7884085277045114"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|                    reviewText|attitude|                   probability|label|prediction|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|the 3ds has an amazing libr...|positive|[0.7720868011644232,0.14251...|  0.0|       0.0|\n",
      "|i just recieved this contro...|positive|[0.7720486391536012,0.14249...|  0.0|       0.0|\n",
      "|i'm ready for microsoft to ...|positive|[0.7709514824506684,0.14396...|  0.0|       0.0|\n",
      "|great game. if you love fig...|positive|[0.7705717607176354,0.14415...|  0.0|       0.0|\n",
      "|an amazing game i have been...|positive|[0.7705717607176354,0.14415...|  0.0|       0.0|\n",
      "|bright and fun. my boyfrien...|positive|[0.7705717607176354,0.14415...|  0.0|       0.0|\n",
      "|easy to configure.  fits pr...|positive|[0.7705228418742072,0.14442...|  0.0|       0.0|\n",
      "|daughter loves it. her favo...|positive|[0.7705014140896247,0.14425...|  0.0|       0.0|\n",
      "|this was a gift for my gran...|positive|[0.7705014140896247,0.14425...|  0.0|       0.0|\n",
      "|i purchased a used nintendo...|positive|[0.7705014140896247,0.14425...|  0.0|       0.0|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n",
    "rfModel = rf.fit(trainingData)\n",
    "\n",
    "# run model on test data\n",
    "predictions = rfModel.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"reviewText\",\"attitude\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6432648903486833"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
